{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some helper stuff for tracking performance over the duration of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_model_timestamp(model_type, kfolds, scores, note):\n",
    "    '''\n",
    "    Parameters:\n",
    "    model_type = string description of the model(s) used to make these scores\n",
    "    kfolds     = how many folds in kfold cross validation used\n",
    "    scores     = list of ROC AUC avg scores of models for each class, floats should be like 0.9784\n",
    "    note       = string, whatever is of note about the model, made a change or whatever\n",
    "    \n",
    "    Returns:\n",
    "    None, but writes (appends) a line to scores.txt in the root directory so that progress can be tracked\n",
    "    The format is:\n",
    "            time(s)~model_type~kfold~avg_roc_auc~toxic_auc~s_toxic_auc~obscene_auc~threat_auc~insult_auc~i_hate_auc~notes\n",
    "            \n",
    "    scores.txt is a tilde '~' seperated CSV like:\n",
    "        time~model_type~kfold~avg_roc_auc~toxic_auc~s_toxic_auc~obscene_auc~threat_auc~insult_auc~i_hate_auc~notes\n",
    "        1520303252~0.9794005980274005~note something\n",
    "    '''\n",
    "\n",
    "    out_text = \"{:10.0f}~{:}~{:2d}~{:0.8f}~{:0.8f}~{:0.8f}~{:0.8f}~{:0.8f}~{:0.8f}~{:0.8f}~{:}\\n\".format(time.time(), \n",
    "                                             model_type, \n",
    "                                             kfolds, \n",
    "                                             np.mean(scores),\n",
    "                                             scores[0],\n",
    "                                             scores[1],\n",
    "                                             scores[2],\n",
    "                                             scores[3],\n",
    "                                             scores[4],\n",
    "                                             scores[5],                                                \n",
    "                                             note)\n",
    "    \n",
    "    with open(\"../scores.txt\", 'a') as out_file:\n",
    "        out_file.write(out_text)\n",
    "        \n",
    "        print(\"wrote:\")\n",
    "        print(out_text)\n",
    "        print(\"to file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and light processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../data/test.csv').fillna(' ')\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize words from both corpuses (corpi?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents='unicode', sublinear_tf=True,\n",
       "        token_pattern='\\\\w{1,}', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=50000)    # 10k was initial\n",
    "\n",
    "word_vectorizer.fit(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (159571, 50000)\n",
      "test shape: (153164, 50000)\n"
     ]
    }
   ],
   "source": [
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "\n",
    "print(\"train shape:\", train_word_features.shape)\n",
    "print(\"test shape:\", test_word_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Spread for class \"toxic\":\n",
      "    0.9709     0.9694     0.9714     0.9721     0.9732     0.9720     0.9684     0.9716     0.9727     0.9729  \n",
      "    CV score for class \"toxic\" is 0.9715\n",
      "\n",
      "CV Spread for class \"severe_toxic\":\n",
      "    0.9838     0.9876     0.9816     0.9862     0.9876     0.9838     0.9883     0.9873     0.9878     0.9889  \n",
      "    CV score for class \"severe_toxic\" is 0.9863\n",
      "\n",
      "CV Spread for class \"obscene\":\n",
      "    0.9884     0.9871     0.9842     0.9854     0.9878     0.9831     0.9868     0.9895     0.9876     0.9862  \n",
      "    CV score for class \"obscene\" is 0.9866\n",
      "\n",
      "CV Spread for class \"threat\":\n",
      "    0.9723     0.9904     0.9919     0.9851     0.9727     0.9880     0.9897     0.9782     0.9870     0.9718  \n",
      "    CV score for class \"threat\" is 0.9827\n",
      "\n",
      "CV Spread for class \"insult\":\n",
      "    0.9790     0.9765     0.9784     0.9754     0.9798     0.9749     0.9762     0.9776     0.9815     0.9790  \n",
      "    CV score for class \"insult\" is 0.9778\n",
      "\n",
      "CV Spread for class \"identity_hate\":\n",
      "    0.9782     0.9723     0.9700     0.9810     0.9626     0.9773     0.9809     0.9814     0.9810     0.9854  \n",
      "    CV score for class \"identity_hate\" is 0.977\n",
      "\n",
      "Total CV score is 0.9803\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "train_features = train_word_features.copy()\n",
    "\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=1337)\n",
    "    \n",
    "#     results = cross_val_score(classifier, train_features, train_target, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "    results = cross_val_score(classifier, train_features, train_target, cv=kfold, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    print('CV Spread for class \"{}\":'.format(class_name))\n",
    "    for result in results:\n",
    "        print(\"    {:0.4f}\".format(result), end=\" \")\n",
    "        \n",
    "    print(\" \")\n",
    "        \n",
    "    cv_score = np.mean(results)\n",
    "    scores.append(cv_score)\n",
    "    \n",
    "    print('    CV score for class \"{}\" is {:0.4}\\n'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(train_features, train_target)\n",
    "    submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {:0.4f}'.format(np.mean(scores)))\n",
    "\n",
    "# write_model_timestamp('logistic regression', NUM_FOLDS, scores, \"first model: word to vec max 100k features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS          AVG ROC AUC\n",
      "toxic          0.9715\n",
      "severe_toxic   0.9863\n",
      "obscene        0.9866\n",
      "threat         0.9827\n",
      "insult         0.9778\n",
      "identity_hate  0.9770\n",
      "Overall Average ROC AUC: 0.9803\n"
     ]
    }
   ],
   "source": [
    "print(\"{: <14} {:}\".format(\"CLASS\", \"AVG ROC AUC\"))\n",
    "\n",
    "for item in zip(class_names, scores):\n",
    "    print(\"{: <14} {:0.4f}\".format(item[0], item[1]))\n",
    "    \n",
    "print(\"Overall Average ROC AUC: {:0.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../submissions/logistic_regression_tfidf_submission.csv.gz', index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.993519</td>\n",
       "      <td>0.120255</td>\n",
       "      <td>0.988003</td>\n",
       "      <td>0.020985</td>\n",
       "      <td>0.860358</td>\n",
       "      <td>0.174008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.009684</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.003706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.035918</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.018623</td>\n",
       "      <td>0.004621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.039584</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.010039</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.012766</td>\n",
       "      <td>0.002737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.993519      0.120255  0.988003  0.020985  0.860358   \n",
       "1  0000247867823ef7  0.009684      0.003237  0.005897  0.001713  0.009233   \n",
       "2  00013b17ad220c46  0.035918      0.003873  0.014029  0.001669  0.018623   \n",
       "3  00017563c3f7919a  0.003429      0.002087  0.003250  0.001071  0.003966   \n",
       "4  00017695ad8997eb  0.039584      0.002397  0.010039  0.001819  0.012766   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.174008  \n",
       "1       0.003706  \n",
       "2       0.004621  \n",
       "3       0.000880  \n",
       "4       0.002737  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153164 entries, 0 to 153163\n",
      "Data columns (total 7 columns):\n",
      "id               153164 non-null object\n",
      "toxic            153164 non-null float64\n",
      "severe_toxic     153164 non-null float64\n",
      "obscene          153164 non-null float64\n",
      "threat           153164 non-null float64\n",
      "insult           153164 non-null float64\n",
      "identity_hate    153164 non-null float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
