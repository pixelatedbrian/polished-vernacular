{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import time\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some helper stuff for tracking performance over the duration of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model_timestamp(model_type, kfolds, scores, note):\n",
    "    '''\n",
    "    Parameters:\n",
    "    model_type = string description of the model(s) used to make these scores\n",
    "    kfolds     = how many folds in kfold cross validation used\n",
    "    scores     = list of ROC AUC avg scores of models for each class, floats should be like 0.9784\n",
    "    note       = string, whatever is of note about the model, made a change or whatever\n",
    "    \n",
    "    Returns:\n",
    "    None, but writes (appends) a line to scores.txt in the root directory so that progress can be tracked\n",
    "    The format is:\n",
    "            time(s)~model_type~kfold~avg_roc_auc~toxic_auc~s_toxic_auc~obscene_auc~threat_auc~insult_auc~i_hate_auc~notes\n",
    "            \n",
    "    scores.txt is a tilde '~' seperated CSV like:\n",
    "        time~model_type~kfold~avg_roc_auc~toxic_auc~s_toxic_auc~obscene_auc~threat_auc~insult_auc~i_hate_auc~notes\n",
    "        1520303252~0.9794005980274005~note something\n",
    "    '''\n",
    "\n",
    "    out_text = \"{:10.0f}~{:}~{:2d}~{:0.8f}~{:0.8f}~{:0.8f}~{:0.8f}~{:0.8f}~{:0.8f}~{:0.8f}~{:}\\n\".format(time.time(), \n",
    "                                             model_type, \n",
    "                                             kfolds, \n",
    "                                             np.mean(scores),\n",
    "                                             scores[0],\n",
    "                                             scores[1],\n",
    "                                             scores[2],\n",
    "                                             scores[3],\n",
    "                                             scores[4],\n",
    "                                             scores[5],                                                \n",
    "                                             note)\n",
    "    \n",
    "    with open(\"../scores.txt\", 'a') as out_file:\n",
    "        out_file.write(out_text)\n",
    "        \n",
    "        print(\"wrote:\")\n",
    "        print(out_text)\n",
    "        print(\"to file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and light processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../data/test.csv').fillna(' ')\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize words from both corpuses (corpi?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Explanation Why the edits made under my userna...\n",
      "0    Yo bitch Ja Rule is more succesful then you'll...\n",
      "Name: comment_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# optionally lemmatize words before vectorizing\n",
    "lemming = WordNetLemmatizer()\n",
    "\n",
    "def stringer(_word):\n",
    "    return \" \".join(lemming.lemmatize(word) for word in _word.split())\n",
    "\n",
    "lem_alltext = all_text.apply(stringer)\n",
    "\n",
    "print(lem_alltext[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I think that your a Fagget get a oife and burn in Hell I hate you 'm sorry we cant have any more sex i'm running out of conndoms\""
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = '''Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169'''\n",
    "\n",
    "test = '''I think that your a Fagget get a oife and burn in Hell I hate you 'm sorry we cant have any more sex i'm running out of conndoms'''\n",
    "\n",
    "print(string.punctuation)\n",
    "\n",
    "\" \".join(lemming.lemmatize(word) for word in test.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation Why the edits made under my userna...\n",
       "0    Yo bitch Ja Rule is more succesful then you'll...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_alltext[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents='unicode', sublinear_tf=True,\n",
       "        token_pattern='\\\\w{1,}', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=50000)\n",
    "\n",
    "word_vectorizer.fit(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (159571, 50000)\n",
      "test shape: (153164, 50000)\n"
     ]
    }
   ],
   "source": [
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "\n",
    "print(\"train shape:\", train_word_features.shape)\n",
    "print(\"test shape:\", test_word_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Spread for class \"toxic\":\n",
      "    0.9709     0.9694     0.9714     0.9721     0.9732     0.9720     0.9684     0.9716     0.9727     0.9729  \n",
      "    CV score for class \"toxic\" is 0.9715\n",
      "\n",
      "CV Spread for class \"severe_toxic\":\n",
      "    0.9838     0.9876     0.9816     0.9862     0.9876     0.9838     0.9883     0.9873     0.9878     0.9889  \n",
      "    CV score for class \"severe_toxic\" is 0.9863\n",
      "\n",
      "CV Spread for class \"obscene\":\n",
      "    0.9884     0.9871     0.9842     0.9854     0.9878     0.9831     0.9868     0.9895     0.9876     0.9862  \n",
      "    CV score for class \"obscene\" is 0.9866\n",
      "\n",
      "CV Spread for class \"threat\":\n",
      "    0.9723     0.9904     0.9919     0.9851     0.9727     0.9880     0.9897     0.9782     0.9870     0.9718  \n",
      "    CV score for class \"threat\" is 0.9827\n",
      "\n",
      "CV Spread for class \"insult\":\n",
      "    0.9790     0.9765     0.9784     0.9754     0.9798     0.9749     0.9762     0.9776     0.9815     0.9790  \n",
      "    CV score for class \"insult\" is 0.9778\n",
      "\n",
      "CV Spread for class \"identity_hate\":\n",
      "    0.9782     0.9723     0.9700     0.9810     0.9626     0.9773     0.9809     0.9814     0.9810     0.9854  \n",
      "    CV score for class \"identity_hate\" is 0.977\n",
      "\n",
      "Total CV score is 0.9803\n",
      "wrote:\n",
      "1520326755~logistic regression~10~0.98031655~0.97147146~0.98628531~0.98659408~0.98270609~0.97783570~0.97700667~first model: logistic regression, word to vec max 50k features, lemmatizing\n",
      "\n",
      "to file\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "train_features = train_word_features.copy()\n",
    "\n",
    "# submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=1337)\n",
    "    \n",
    "#     results = cross_val_score(classifier, train_features, train_target, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "    results = cross_val_score(classifier, train_features, train_target, cv=kfold, scoring='roc_auc')\n",
    "    \n",
    "    print('CV Spread for class \"{}\":'.format(class_name))\n",
    "    for result in results:\n",
    "        print(\"    {:0.4f}\".format(result), end=\" \")\n",
    "        \n",
    "    print(\" \")\n",
    "        \n",
    "    cv_score = np.mean(results)\n",
    "    scores.append(cv_score)\n",
    "    \n",
    "    print('    CV score for class \"{}\" is {:0.4}\\n'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(train_features, train_target)\n",
    "#     submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {:0.4f}'.format(np.mean(scores)))\n",
    "\n",
    "write_model_timestamp('logistic regression', NUM_FOLDS, scores, \"first model: logistic regression, word to vec max 50k features, lemmatizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS          AVG ROC AUC\n",
      "toxic          0.9698\n",
      "severe_toxic   0.9859\n",
      "obscene        0.9854\n",
      "threat         0.9828\n",
      "insult         0.9765\n",
      "identity_hate  0.9761\n"
     ]
    }
   ],
   "source": [
    "print(\"{: <14} {:}\".format(\"CLASS\", \"AVG ROC AUC\"))\n",
    "\n",
    "for item in zip(class_names, scores):\n",
    "    print(\"{: <14} {:0.4f}\".format(item[0], item[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
