{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors   # allows use of gamma to tune cmaps\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "# import plotly.offline as py\n",
    "# import plotly.graph_objs as go\n",
    "# py.init_notebook_mode(connected=True)\n",
    "\n",
    "# import holoviews as hv\n",
    "# hv.notebook_extension('plotly')\n",
    "\n",
    "# import plotly\n",
    "\n",
    "# plotly.tools.set_credentials_file(username='pixelatedbrian', api_key='GbiE5PkSLPv9HjnrU7E8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and light processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../data/test.csv').fillna(' ')\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize words from both corpuses (corpi?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=25000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents='unicode', sublinear_tf=True,\n",
       "        token_pattern='\\\\w{1,}', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=25000)    # 10k was initial\n",
    "\n",
    "word_vectorizer.fit(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (159571, 25000)\n",
      "test shape: (153164, 25000)\n"
     ]
    }
   ],
   "source": [
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "\n",
    "print(\"train shape:\", train_word_features.shape)\n",
    "print(\"test shape:\", test_word_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143346, 8)\n",
      "(10000,)\n",
      "[3231 4769 5085 8203 3333 5850 8748 5249 3098 6608]\n",
      "(5000, 8)\n"
     ]
    }
   ],
   "source": [
    "proto = train.iloc[:100, :]\n",
    "\n",
    "rage = train.loc[np.sum(train.iloc[:,2:], axis=1) >= 1]\n",
    "\n",
    "# this list of messages is much bigger, and also get unflagged ones, not just random ones\n",
    "calm = train.loc[np.sum(train.iloc[:,2:], axis=1) == 0]\n",
    "\n",
    "\n",
    "print(calm.shape)\n",
    "boink = np.random.permutation(10000)\n",
    "\n",
    "# boink = boink[:5000]\n",
    "\n",
    "print(boink.shape)\n",
    "print(boink[:10])\n",
    "\n",
    "calm = pd.DataFrame(np.take(calm.values, boink[:5000], axis=0), columns=rage.columns)\n",
    "rage = pd.DataFrame(np.take(rage.values, boink, axis=0), columns=calm.columns)\n",
    "\n",
    "print(calm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      "id               10000 non-null object\n",
      "comment_text     10000 non-null object\n",
      "toxic            10000 non-null object\n",
      "severe_toxic     10000 non-null object\n",
      "obscene          10000 non-null object\n",
      "threat           10000 non-null object\n",
      "insult           10000 non-null object\n",
      "identity_hate    10000 non-null object\n",
      "dtypes: object(8)\n",
      "memory usage: 625.1+ KB\n",
      "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
      "       'insult', 'identity_hate'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 8 columns):\n",
      "id               5000 non-null object\n",
      "comment_text     5000 non-null object\n",
      "toxic            5000 non-null object\n",
      "severe_toxic     5000 non-null object\n",
      "obscene          5000 non-null object\n",
      "threat           5000 non-null object\n",
      "insult           5000 non-null object\n",
      "identity_hate    5000 non-null object\n",
      "dtypes: object(8)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "rage.info()\n",
    "\n",
    "print(rage.columns)\n",
    "calm.info()\n",
    "\n",
    "calm.keys = rage.keys\n",
    "\n",
    "rage_vec_words = word_vectorizer.transform(rage.loc[:, \"comment_text\"])\n",
    "calm_vec_words = word_vectorizer.transform(calm.loc[:, \"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 25000)\n"
     ]
    }
   ],
   "source": [
    "rager = rage_vec_words.todense()\n",
    "calms = calm_vec_words.todense()\n",
    "\n",
    "calm_rage = np.vstack((calms, rager))\n",
    "\n",
    "print(calm_rage.shape)\n",
    "# pca_snip = calm_rage.todense()\n",
    "pca = PCA(n_components=250)\n",
    "pca_result = pca.fit_transform(calm_rage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29111845303576656"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 15000 samples in 0.203s...\n",
      "[t-SNE] Computed neighbors for 15000 samples in 95.662s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 15000\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 15000\n",
      "[t-SNE] Mean sigma: 0.073668\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 94.028397\n",
      "[t-SNE] Error after 300 iterations: 4.026939\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=3, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(pca_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_dim = tsne_results[:, 0]\n",
    "y_dim = tsne_results[:, 1]\n",
    "z_dim = tsne_results[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calm_x = x_dim[10000:-1]\n",
    "calm_y = y_dim[10000:-1]\n",
    "calm_z = z_dim[10000:-1]\n",
    "\n",
    "rage_x = x_dim[:10000]\n",
    "rage_y = y_dim[:10000]\n",
    "rage_z = z_dim[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rage_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################3\n",
    "### For non-toxic class     #######\n",
    "###################################\n",
    "\n",
    "for aaa, ang in enumerate(range(0, 360, 1)):\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(10,10))\n",
    "    \n",
    "    COUNT = 5000\n",
    "    \n",
    "    ax.scatter(calm_x[:COUNT], calm_y[:COUNT], calm_z[:COUNT],\n",
    "               zdir='z',\n",
    "               cmap=\"viridis\",\n",
    "               c=calm_z[:COUNT], s=200, label=\"Non-Toxic\", alpha=0.3)\n",
    "    \n",
    "#     for idx in range(2, 8):\n",
    "#         idy = idx - 2\n",
    "#         if idy != 0 and idy != 4:\n",
    "#         #     # for col in colors:\n",
    "#         #     temp = indices[labels[:,idx]==1]\n",
    "#         #     temp = temp[:3000]\n",
    "\n",
    "#             ax.scatter(\n",
    "#                     rage_x[rage.iloc[:,idx]==1][:counts[idy]],\n",
    "#                     rage_y[rage.iloc[:,idx]==1][:counts[idy]],\n",
    "#                     rage_z[rage.iloc[:,idx]==1][:counts[idy]],\n",
    "#                     zdir='z',\n",
    "#                     color=colors[idy],\n",
    "#                     label=class_names[idy],\n",
    "#                     s=20,\n",
    "#                     marker=\"o\",\n",
    "#                     alpha=0.1)\n",
    "#             ax.set_xticks([])\n",
    "#             ax.set_yticks([])\n",
    "#             ax.set_zticks([])\n",
    "    ax.set_xlim(-3.0, 3.0)\n",
    "    ax.set_ylim(-4, 3)\n",
    "    ax.set_zlim(-3, 3)\n",
    "    ax.w_xaxis.set_pane_color((0.98, 0.98, 0.98, 1.0))\n",
    "    ax.w_yaxis.set_pane_color((0.98, 0.98, 0.98, 1.0))\n",
    "    ax.w_zaxis.set_pane_color((0.98, 0.98, 0.98, 1.0))\n",
    "    ax.set_axis_off()\n",
    "    ax.autoscale_view(tight=True)\n",
    "\n",
    "    ax.legend(fontsize=32, loc=1)\n",
    "    ax.view_init(15 + 15 * np.sin(ang * np.pi / 180), ang)\n",
    "    \n",
    "#     fig = plt.gcf()\n",
    "#     py.plot_mpl(fig, filename=\"mpl-colormaps-simple\")\n",
    "    \n",
    "    filename = \"../imgs/{:03d}.png\".format(aaa)\n",
    "    plt.savefig(filename, dpi=100)\n",
    "    plt.gca()\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>527218d0d2230e7a</td>\n",
       "      <td>FUCK YOU FUCK YOU FUCK YOU FUCK YOU FUCK YOU</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7a9ed4958bdf833a</td>\n",
       "      <td>, who blantently privledge shit over quality</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83a45c3f8fda2e5a</td>\n",
       "      <td>\"\\n\\n Hey...... I did NOT attack other wikiped...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d5aca4e1da09a8e7</td>\n",
       "      <td>\"\\n\\nIT IS TEH SAME DANCE. IT IS JUST BECAUSE ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55658093e3ad479c</td>\n",
       "      <td>Welcome, Korean assh*le's page.\\nWhy don't you...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text toxic  \\\n",
       "0  527218d0d2230e7a       FUCK YOU FUCK YOU FUCK YOU FUCK YOU FUCK YOU     1   \n",
       "1  7a9ed4958bdf833a       , who blantently privledge shit over quality     1   \n",
       "2  83a45c3f8fda2e5a  \"\\n\\n Hey...... I did NOT attack other wikiped...     1   \n",
       "3  d5aca4e1da09a8e7  \"\\n\\nIT IS TEH SAME DANCE. IT IS JUST BECAUSE ...     1   \n",
       "4  55658093e3ad479c  Welcome, Korean assh*le's page.\\nWhy don't you...     1   \n",
       "\n",
       "  severe_toxic obscene threat insult identity_hate  \n",
       "0            0       1      0      1             0  \n",
       "1            0       0      0      0             0  \n",
       "2            0       0      0      0             0  \n",
       "3            0       0      0      0             0  \n",
       "4            0       0      0      0             0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rage[rage.loc[:,'toxic']==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "### For toxic type classes  #######\n",
    "###################################\n",
    "\n",
    "for aaa, ang in enumerate(range(0, 360, 1)):\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    gs = gridspec.GridSpec(3, 4)  # allow the merging of plots\n",
    "#     gs.update(left=-0.5, right=0.05, wspace=0.0, hspace=0.0)\n",
    "    ax = plt.subplot(gs[:,0:2], projection='3d')\n",
    "    \n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(10,10))\n",
    "    \n",
    "    COUNT = 5000\n",
    "    \n",
    "    ax.scatter(calm_x[:COUNT], calm_y[:COUNT], calm_z[:COUNT],\n",
    "               zdir='z',\n",
    "               cmap=\"viridis\",\n",
    "               c=calm_z[:COUNT], s=75, label=\"Non-Toxic\", alpha=1.0)\n",
    "    \n",
    "    ax.set_xlim(-3.0, 3.0)\n",
    "    ax.set_ylim(-4, 3)\n",
    "    ax.set_zlim(-3, 3)\n",
    "    ax.w_xaxis.set_pane_color((0.98, 0.98, 0.98, 1.0))\n",
    "    ax.w_yaxis.set_pane_color((0.98, 0.98, 0.98, 1.0))\n",
    "    ax.w_zaxis.set_pane_color((0.98, 0.98, 0.98, 1.0))\n",
    "    \n",
    "#     ax.set_facecolor(\"black\")\n",
    "    \n",
    "    ax.set_axis_off()\n",
    "    ax.autoscale_view(tight=True)\n",
    "    ax.view_init(15 + 15 * np.sin(ang * np.pi / 180), ang)\n",
    "    ax.set_title(\"Non-Toxic Comment\")\n",
    "    \n",
    "        # help organize different characteristics\n",
    "    class_names = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "    \n",
    "    for class_num, _class in enumerate(class_names):\n",
    "        _colors = [\"Greens_r\", \"summer\", \"spring\", \"afmhot\", \"copper\", \"cool\"]\n",
    "\n",
    "        sizes = [20, 40, 20, 40, 20, 40]\n",
    "        alphas = [0.75, 0.9, 0.75, 0.75, 0.75, 0.9]\n",
    "        markers = [\"o\", \"o\", \"^\", \"X\", \"o\", \"^\"]\n",
    "        counts = [20, 40, 20, 40, 20, 40]\n",
    "\n",
    "\n",
    "        COUNT = 5000\n",
    "        \n",
    "        ################################\n",
    "        ### Subplot maneuvering  #######\n",
    "        ################################        \n",
    "        \n",
    "        # could do an alg or could be like hecka lazy\n",
    "        plt_rows = [0, 0, 1, 1, 2, 2]\n",
    "        plt_cols = [2, 3, 2, 3, 2, 3]\n",
    "        \n",
    "        ax = plt.subplot(gs[plt_rows[class_num], plt_cols[class_num]], projection='3d')\n",
    "\n",
    "\n",
    "        idx = class_num\n",
    "        idy = idx + 2\n",
    "\n",
    "        sampler = np.random.permutation(COUNT)\n",
    "        class_matches = rage.iloc[:, idy]==1   # big list of booleans to filter 8 columns to the topic wanted\n",
    "\n",
    "        temp_x = rage_x[rage.iloc[:, idy]==1]\n",
    "        temp_y = rage_y[rage.iloc[:, idy]==1]\n",
    "        temp_z = rage_z[rage.iloc[:, idy]==1]\n",
    "    #     print(\"shape of temp_x\", temp_x.shape)\n",
    "\n",
    "        # if the size of the matches is greater than the count\n",
    "        # then subsample using the sampler\n",
    "        if temp_x.shape[0] > COUNT:\n",
    "            temp_x = np.take(temp_x, sampler)\n",
    "            temp_y = np.take(temp_y, sampler)\n",
    "            temp_z = np.take(temp_z, sampler)\n",
    "\n",
    "\n",
    "        v_offset = np.min(temp_z)\n",
    "\n",
    "        c_off = 1.0\n",
    "        _c = (temp_z - v_offset)/2 + c_off\n",
    "\n",
    "    #     print(\"max c\", np.max(_c))\n",
    "\n",
    "        _c[np.argmax(_c)] = 7 + c_off   # set a nail to stretch the cmap to the look that we want\n",
    "        _c[np.argmin(_c)] = 0   # set a lower one too\n",
    "\n",
    "        ax.scatter(temp_x,\n",
    "                   temp_y,\n",
    "                   temp_z,\n",
    "                   zdir='z',\n",
    "                   cmap=_colors[idx],\n",
    "                   c=_c,\n",
    "                   s=sizes[idx],\n",
    "    #                norm=colors.PowerNorm(gamma=3.25/3.5),\n",
    "#                    label=class_names[idx],\n",
    "                   alpha=alphas[idx])\n",
    "\n",
    "        ax.set_title(class_names[idx])\n",
    "        ax.set_xlim(-3.0, 3.0)\n",
    "        ax.set_ylim(-4, 3)\n",
    "        ax.set_zlim(-3, 3)\n",
    "    #     ax.w_xaxis.set_pane_color((0.98, 0.98, 0.98, 1.0))\n",
    "    #     ax.w_yaxis.set_pane_color((0.98, 0.98, 0.98, 1.0))\n",
    "    #     ax.w_zaxis.set_pane_color((0.98, 0.98, 0.98, 1.0))\n",
    "        ax.set_axis_off()\n",
    "        ax.autoscale_view(tight=True)\n",
    "\n",
    "#         ax.set_facecolor(\"black\")\n",
    "        \n",
    "#         ax.legend(fontsize=14, loc=1)\n",
    "        ax.view_init(15 + 15 * np.sin(ang * np.pi / 180), ang)\n",
    "\n",
    "    \n",
    "#     ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "\n",
    "#     COUNT = 5000\n",
    "\n",
    "    plt.subplots_adjust(top=1.0, bottom=0.0, left=0.0, right=1.0, wspace=0.0, hspace=0.0)\n",
    "    filename = \"../imgs/{:03d}.png\".format(aaa)\n",
    "    plt.savefig(filename, dpi=100)\n",
    "#     plt.gca()\n",
    "#     plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.8704715 , -0.02555365, -2.241838  , ...,  0.4592499 ,\n",
       "        0.36266276,  1.9928123 ], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dim[rage.iloc[:,2]==1]\n",
    "# x_dim[rage.iloc[:,2]==1][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%opts Scatter3D [width=800 height=800 camera_zoom=200 alpha=0.5 color_index=2] (size=10 cmap='viridis')\n",
    "\n",
    "# hv.Scatter3D(zip(calm_x[:3000],\n",
    "#             calm_y[:3000],\n",
    "#             calm_z[:3000]))\n",
    "\n",
    "# hv.Scatter3D(zip(rage_x[rage.iloc[:,0]==1], rage_y[rage.iloc[:,0]==1], rage_z[rage.iloc[:,0]==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for x in range(6):\n",
    "    print((x % 3) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
